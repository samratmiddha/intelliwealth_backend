try:
    from urllib.request import urlopen
except ImportError:
    from urllib2 import urlopen
import certifi
import json
import pandas as pd
from datetime import datetime

def get_stock_data(ticker, api_key):
    """Get comprehensive stock data from multiple endpoints"""
    all_data = {}
    
    quote_url = f"https://financialmodelingprep.com/api/v3/quote/{ticker}?apikey={api_key}"
    response = urlopen(quote_url, cafile=certifi.where())
    quote_data = json.loads(response.read().decode("utf-8"))
    if quote_data and isinstance(quote_data, list):
        all_data["quote"] = quote_data[0]
    
    try:
        ratios_url = f"https://financialmodelingprep.com/api/v3/ratios/{ticker}?apikey={api_key}&limit=1"
        response = urlopen(ratios_url, cafile=certifi.where())
        ratios_data = json.loads(response.read().decode("utf-8"))
        if ratios_data and isinstance(ratios_data, list):
            all_data["ratios"] = ratios_data[0]
    except Exception:
        pass
    
    try:
        metrics_url = f"https://financialmodelingprep.com/api/v3/key-metrics/{ticker}?apikey={api_key}&limit=1"
        response = urlopen(metrics_url, cafile=certifi.where())
        metrics_data = json.loads(response.read().decode("utf-8"))
        if metrics_data and isinstance(metrics_data, list):
            all_data["metrics"] = metrics_data[0]
    except Exception:
        pass
    
    try:
        profile_url = f"https://financialmodelingprep.com/api/v3/profile/{ticker}?apikey={api_key}"
        response = urlopen(profile_url, cafile=certifi.where())
        profile_data = json.loads(response.read().decode("utf-8"))
        if profile_data and isinstance(profile_data, list):
            all_data["profile"] = profile_data[0]
    except Exception:
        pass
    
    return all_data

def prepare_financial_data(data):
    """Transform nested data into flattened DataFrame"""
    flattened_data = {}
    
    current_date = datetime.now().strftime("%Y-%m-%d")
    flattened_data["data_retrieved_date"] = current_date
    flattened_data["analysis_date"] = current_date
    
    for section, section_data in data.items():
        if isinstance(section_data, dict):
            for key, value in section_data.items():
                flattened_data[f"{section}_{key}"] = value
    
    df = pd.DataFrame([flattened_data])
    df["data_description"] = (
        f"This is current financial data for the stock as of {current_date}. "
        "It includes quote information, financial ratios, key metrics, and company profile data. "
        "All monetary values are in USD unless otherwise specified."
    )
    
    return df

import re

def parse_financial_report(result_str):
    """
    Parse the LLM result string into a structured dictionary.
    This is a simple parser for the specific format generated by the LLM.
    """
    data = {}
    # Symbol and date
    symbol_match = re.search(r'for Symbol "?([A-Z]+)"?', result_str)
    if symbol_match:
        data["symbol"] = symbol_match.group(1)
    date_match = re.search(r'as of ([\w\s,()]+)', result_str)
    if date_match:
        data["as_of"] = date_match.group(1).strip()

    # Extract key metrics using regex
    patterns = [
        ("revenue_per_share", r"Revenue Per Share:.*?\$([-\d\.]+)"),
        ("net_income_per_share", r"Net Income Per Share:.*?\$([-\d\.]+)"),
        ("operating_cash_flow_per_share", r"Operating Cash Flow Per Share:.*?\$([-\d\.]+)"),
        ("free_cash_flow_per_share", r"Free Cash Flow Per Share:.*?\$([-\d\.]+)"),
        ("cash_per_share", r"Cash Per Share:.*?\$([-\d\.]+)"),
        ("book_value_per_share", r"Book Value Per Share:.*?\$([-\d\.]+)"),
        ("price_to_fair_value_ratio", r"Price to Fair Value Ratio:.*?([-\d\.]+)"),
        ("current_ratio", r"Current Ratio:.*?([-\d\.]+)"),
        ("quick_ratio", r"Quick Ratio:.*?([-\d\.]+)"),
        ("average_daily_volume_million", r"average daily trading volume.*?([-\d\.]+) million"),
        ("total_volume_million", r"total of ([\d\.]+) million shares traded"),
        ("open", r"opening price.*?\$([-\d\.]+)"),
        ("previous_close", r"closing price.*?\$([-\d\.]+)"),
        ("eps", r"Earnings Per Share.*?\$([-\d\.]+)"),
        ("pe_ratio", r"P/E ratio is ([\w\s\.]+)"),
        ("future_earnings_announcement", r"next earnings announcement.*?is scheduled for ([\w\s,:]+)\.")
    ]
    for key, pat in patterns:
        m = re.search(pat, result_str, re.IGNORECASE)
        if m:
            val = m.group(1).strip()
            # Convert to float if possible
            try:
                val = float(val.replace(',', ''))
            except Exception:
                pass
            data[key] = val

    return data

def run_langchain_query(df, question):
    """Process the DataFrame with LangChain to answer the financial query using the asset's JSON data as intermediary"""
    import json
    from langchain_core.documents import Document
    from langchain.text_splitter import RecursiveCharacterTextSplitter
    from langchain_community.embeddings import HuggingFaceEmbeddings
    from langchain.vectorstores import Chroma
    from langchain.prompts import PromptTemplate
    from langchain.chains import RetrievalQA
    from langchain_community.llms import Ollama

    json_data = df.to_dict(orient="records")[0]
    doc_content = json.dumps(json_data, indent=2)
    documents = [Document(page_content=doc_content)]
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    texts = text_splitter.split_documents(documents)
    hg_embeddings = HuggingFaceEmbeddings()
    PERSIST_DIR = "docs/chroma_rag/"
    vectorstore = Chroma.from_documents(
        documents=texts,
        collection_name="stock_data",
        embedding=hg_embeddings,
        persist_directory=PERSIST_DIR
    )
    retriever = vectorstore.as_retriever(search_kwargs={"k": 5})
    template = """
IMPORTANT INSTRUCTION: You are a Financial Analyst providing information SOLELY based on the data provided below. 
Do NOT refer to any other knowledge about this company or defer to external sources.

CURRENT DATA: 
{context}

USER QUERY: {question}

YOUR TASK:
1. Analyze ONLY the data provided above
2. Answer the query directly using ONLY this data
3. If specific information isn't in the data, clearly state what IS available and provide that information instead
4. Format your response in a professional, easy-to-read format
5. Do NOT suggest visiting websites or getting data elsewhere
6. Do NOT apologize for limitations - just work with what you have
7. ASSUME ALL DATA IS CURRENT AND ACCURATE

RESPONSE (using only the data shown above):
"""
    PROMPT = PromptTemplate(input_variables=["context", "question"], template=template)
    llm = Ollama(model="mistral", temperature=0.01)
    qa = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=retriever,
        chain_type_kwargs={"prompt": PROMPT},
        return_source_documents=True
    )
    response = qa({"query": question})
    result = response["result"]
    # Parse the result string into a dict before returning
    parsed = parse_financial_report(result)
    return {"parsed": parsed, "raw": result}